[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Book of Workshops",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "Git-and-GitHub/index.html",
    "href": "Git-and-GitHub/index.html",
    "title": "Getting Started with Git and GitHub",
    "section": "",
    "text": "Introduction\nGit and GitHub are two of the most popular and often utilized development tools for project version control on the market. Regarless of their status, they remain challenging tools for new users to get started with. Many resources cover siloed or non-generalizable topics about one or the other. Few resources offer a one-stop-shop introduction that quickly takes users through initial set-up and through basic use cases with individual or collaborative projects.\nIn this workshop, we aim to merge the worlds of Git and GitHub in an approachable but comprehensive format that is accessible to people who have never used Git or GitHub before or those interested in improving their existing workflows. Maybe you are like I was, flying blind using the bare minimum of what Git and GitHub has to offer!\nOver the course of the workshop chapter, we will take you through:\nReal-world examples with questions/answers and challenge questions/solutions are provided for:",
    "crumbs": [
      "Getting Started with Git and GitHub"
    ]
  },
  {
    "objectID": "Git-and-GitHub/index.html#introduction",
    "href": "Git-and-GitHub/index.html#introduction",
    "title": "Getting Started with Git and GitHub",
    "section": "",
    "text": "Git and GitHub account set-up with configurations by either SSH keys or HTTPS urls.\nDetailed walk through the standard Git version control workflow and interactions with the remote repository stored in GitHub.\nAnother detailed walk through collaborating on projects with a team through GitHub.\n\n\n\nAdding a local, Git initiated, project to GitHub for the first time.\nCloning an existing repository as a ‚Äúclean-break‚Äù copy for the first time.\nCollaborations with a shared GitHub repository (invite friends to have the full experience!)",
    "crumbs": [
      "Getting Started with Git and GitHub"
    ]
  },
  {
    "objectID": "Git-and-GitHub/index.html#about-the-data",
    "href": "Git-and-GitHub/index.html#about-the-data",
    "title": "Getting Started with Git and GitHub",
    "section": "About the Data",
    "text": "About the Data\nThe Johns Hopkins Coronavirus Resource Center (JHU CRC) tracked and compiled global COVID-19 pandemic data from January 22, 2020 and March 10, 2023. These data are publically available through their two GitHub repositories. We imported two datasets for this workshop content:\n\nCumulative vaccination counts for the U.S. from their GovEX/COVID-19 GitHub repository. The raw data used in the analysis script can be found in the data_tables/vaccine_data/us_data/time_series subdirectory (original source).\nCumulative case and death counts for the U.S. from their CSSE GitHub. The raw data for these two datasets used in the analysis can be found in the csse_covid_19_data/csse_covid_19_time_series subdirectory (original source). Both time_series_covid19_confirmed_US.csv and time_series_covid19_deaths_US.csv were used.\n\nThe data dictionaries provided by JHU CRC can be found here: Vaccinations Dataset Data Dictionary and Cases and Deaths Datasets Data Dictionary. For our purposes, we conducted some data cleaning, harmonization, and smoothing using an isotonic regression. This included harmonizing the U.S. Census Bureau‚Äôs 2010 to 2019 population projections with 2020 to 2023 vintages.\nDetails about these steps can be found in the Git-and-GitHub/R directory of this workshop‚Äôs GitHub repository (Direct Link to Code). The cleaned datasets used in this workshop can be found in the Git-and-GitHub/Data directory of this workshop‚Äôs GitHub repository (Direct Link to Code)",
    "crumbs": [
      "Getting Started with Git and GitHub"
    ]
  },
  {
    "objectID": "Git-and-GitHub/index.html#our-choice-resources",
    "href": "Git-and-GitHub/index.html#our-choice-resources",
    "title": "Getting Started with Git and GitHub",
    "section": "Our Choice Resources",
    "text": "Our Choice Resources\nWhile there are many resources on Git and GitHub out there, we have curated a few additional sites and tutorials that we found support and expound on our presentation. Some of these sources will cover the basics like we will be doing today, while others include advanced materials and guides that will help you develop more advanced skills as you gain experience.\n\nYale‚Äôs Center for Research Computing workshop ‚ÄúVersion Control by Git‚Äù by Kaylea Nelson\nYale‚Äôs Harvey Cushing/John Hay Whitney Medical Library workshop ‚ÄúGit & GitHub: An Introduction To Version Contro‚Äù by Justin DeMayo\n‚ÄúGetting Git Right‚Äù by Atlassian\nGit and GitHub Tutorial by W3 Schools\nIntroduction to GitHub by GitHub\n‚ÄúHappy Git and GitHub for user‚Äù by Jenny Bryan",
    "crumbs": [
      "Getting Started with Git and GitHub"
    ]
  },
  {
    "objectID": "Git-and-GitHub/index.html#accessing-the-materials",
    "href": "Git-and-GitHub/index.html#accessing-the-materials",
    "title": "Getting Started with Git and GitHub",
    "section": "Accessing the Materials",
    "text": "Accessing the Materials\n\nSlides, Handouts, and Other Materials\nDownload the complete slide deck with annotations and the in-person workshop handout. Comments were saved in the bottom left of each slide, and references for this webpage are in its Appendix.\nCOMING SOON\n\n\nCodespaces\nIn this workshop you will need to access the R code we have prepared for the worked through example and challenge questions. If you have not already, you will need to download R to your local device, and we suggest using the integrated development environment (IDE) software RStudio. Accessing the code for this workshop requires that you have git installed on your local device, a GitHub account, and you have configured the two. If you have not done this, go through Accounts and Configurations first.\n\n\n\n\n\n\nImportant\n\n\n\n\n\nThis workshop was generated using R (v 4.4.3) in the RStudio IDE (v 2024.12.1+563). renv() is included to reproduce the same coding enviroment, storing all the relevant packages and package versions needed in the code. If you experience trouble running the scripts, you might want to check that the environment was initialized and that you are using the same version of R and RStudio.\n\n\n\nTwo GitHub repositories have been created to practice using git and GitHub:\n\nSolo projects: ysph-dsde/JHU-CRC-Vaccinations\nGroup projects: ysph-dsde/JHU-CRC-Cases-and-Deaths\n\nIn order to practice your skills with git and GitHub using our codespaces, you will need to create a ‚Äúclean-break‚Äù copy of both repositories. This will fully decouple the codespace connections from the ysph-dsde GitHub accout, and allow you full access to its contents. After you have copied the repository to your personal GitHub, you will need to clone the codespace to your local device and initialize the environment.\nBelow we have detailed how to do all three steps. Notice that there are two methods to do this: by the GitHub Importer tool or your command-line application (i.e.¬†Terminal for Macs and Windows Terminal for windows). We suggest you attempt the ‚ÄúGitHub Importer‚Äù tool option first, and if that fails to follow the command-line steps. Please note that the importer tool will sometimes take a few minutes to fully transfer over the files.\n\n\nMaking a Clean-Break Copy\n\nMETHOD 1: Copying Using GitHub Importer\n\n\n\n\n\n\nNote\n\n\n\nThis method is not a Fork. You can learn more about GitHub Importer here.\n\n\n\nLog in to your personal GitHub account.\nIn the top-right of the page navigation bar, select the   dropdown menu and click  Import repository.\nFill out the following sections:\n\nYour source repository details: Paste the https url of the repositories listed above. No credentials are required for this action.\nYour new repository details: Adjust the GitHub account owner as needed and create the name for the new repository. It is good practice to initially set the repository to ‚ÄúPrivate‚Äù.\n\nClick the Begin import button to copy the codespace.\nAfter a few minutes, the newly created GitHub repository webpage will open up.\n\nIf this method is successful, then proceed to the Cloning the Copied Repository section. If this is not successful, you can try using the command-line application menthod detailed in Method 2.\n\n\nMETHOD 2: Copying Using The Command-Line Application\nThese directions follow GitHub‚Äôs duplicating a repository page.\n\nLog in to your personal GitHub account.\nNavigate to the ysph-dsde GitHub repository you want to copy by either searching for it by name or opening the url provided above.\nNear the right side of the page there will be a  ¬†Begin import  button to click. In its drop down menu under the ‚ÄúLocal‚Äù tab you will see options to copy the SSH key or HTTPS url to the repository.\nFor example, if the repository name is ‚ÄúORIGINAL-REPOSITORY‚Äù they will look like:\n\n\nCommand-Line Application\n\n# SSH\ngit@github.com:ysph-dsde/ORIGINAL-REPOSITORY.git\n\n# HTTPS\nhttps://github.com/ysph-dsde/ORIGINAL-REPOSITORY.git\n\nDepending on your Git/GitHub configurations, you will copy one of these for the remainder of the steps.\n\n\n\n\n\n\n\nImportant\n\n\n\nSSH keys or HTTPS urls are file transfer protocols that are used to pass information between your local git configured directory to the remote GitHub repository. Only one protocol can be set up for one Git/GitHub connection.\n\n\n\nOpen the command-line application (i.e.¬†Terminal for Macs and Windows Terminal for windows) and navigate to the file location you want to temporarily store the repository copy.\n\n\nCommand-Line Application\n\ncd \"/file_location/\"\n\nClone a bare copy of the original repository using its SSH key or HTTPS url:\n\n\nCommand-Line Application\n\n# SSH\ngit clone --bare git@github.com:ysph-dsde/ORIGINAL-REPOSITORY.git\n\n# HTTPS\ngit clone --bare https://github.com/ysph-dsde/ORIGINAL-REPOSITORY.git\n\nOpen the project file.\n\n\nCommand-Line Application\n\ncd \"ORIGINAL-REPOSITORY.git\"\n\nBack in GitHub, in the top-right of the page navigation bar select the   dropdown menu and click  New repository.\nFill out the following sections:\n\nAdjust the GitHub account owner as needed and create the name for the new repository.\nIt is good practice to initially set the repository to ‚ÄúPrivate‚Äù.\nDo NOT use a template or include a description, README.md, .gitignore, or license.\n\nIn the newly created GitHub repository under ‚ÄúQuick setup‚Äù you will find the repository‚Äôs SSH key or HTTPS url. Copy this.\nBack in the command-line application, push a mirror of the cloned git file to your newly created GitHub repository using its SSH key or HTPPS url:\n\n\nCommand-Line Application\n\n# SSH\ngit push --mirror git@github.com:EXAMPLE-USER/NEW-REPOSITORY.git\n\n# HTTPS\ngit push --mirror https://github.com/EXAMPLE-USER/NEW-REPOSITORY.git\n\nRefresh the new GitHub reposiotry webpage to confirm the push was successful.\nDelete the bare cloned file used to create a new remote repository.\n\n\nCommand-Line Application\n\ncd ..                                   # Go back one file location\nrm -rf ORIGINAL-REPOSITORY.git          # Delete the bare clone\n\nThis completes creating a clean-break copy of the ysph-dsde repository codespace. Proceed with cloning the newly made repository to your local device in the following section.\n\n\n\n\nCloning the Copied Repository\nNow that you have copied this repository into your own GitHub, you are ready to proceed with a standard clone to your local device.\n\nCopy the SSH key or HTTPS url to the newly created repository in your GitHub account by finding the codes under the  ¬†Begin import  button.\n\n\nCommand-Line Application\n\n# SSH\ngit@github.com:ysph-dsde/NEW-REPOSITORY.git\n\n# HTTPS\nhttps://github.com/ysph-dsde/NEW-REPOSITORY.git\n\nIn the command-line application (i.e.¬†Terminal for Macs and Windows Terminal for windows) navigate to the file location you want to store the repository.\n\n\nCommand-Line Application\n\ncd \"/file_location/\"\n\nClone the the repository.\n\n\nCommand-Line Application\n\n# using SSH\ngit clone git@github.com:EXAMPLE-USER/NEW-REPOSITORY.git\n\n# or using HTTPS\ngit clone https://github.com/EXAMPLE-USER/NEW-REPOSITORY.git\n\nOPTIONAL: You can reset the repository history, which will clear the previous commits, by running the following block of code (Source: StackExchange by Zeelot).\n\n\nCommand-Line Application\n\ngit checkout --orphan tempBranch         # Create a temporary branch\ngit add -A                               # Add all files and commit them\ngit commit -m \"Reset the repo\"\ngit branch -D main                       # Deletes the main branch\ngit branch -m main                       # Rename the current branch to main\ngit push -f origin main                  # Force push main branch to GitHub\ngit gc --aggressive --prune=all          # Remove the old files\n\n\n\n\nInitializing the Environment\nAfter cloning the codespace to your local device, you will need to initialize the environment using renv(). This will install all packages and versions used in the workshop, thus creating a reproducible coding environemnt.\n\nIn the command-line application (i.e.¬†Terminal for Macs and Windows Terminal for windows) navigate to the file location you want to store the repository.\n\n\nCommand-Line Application\n\ncd \"/file_location/\"\n\nLaunch the project by opening the *.Rproj in RStudio.\nIn the R console, activate the enviroment by runing the following lines of code:\n\n\nRStudio Console\n\nrenv::init()          # Initialize the project\nrenv::restore()       # Download packages and their version saved in the lockfile.\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are asked to update packages, say no. The renv() is intended to recreate the same environment under which the project was created, making it reproducible. You are ready to proceed when running renv::restore() gives the output:\n\n\nRStudio Output\n\n- The library is already synchronized with the lockfile.\n\nIf you experience any trouble with this step, you might want to confirm that you are using R (v 4.4.3) in the RStudio IDE (v 2024.12.1+563). You can also read more about renv() in their vignette.",
    "crumbs": [
      "Getting Started with Git and GitHub"
    ]
  },
  {
    "objectID": "Git-and-GitHub/Pages/git-github-setup.html",
    "href": "Git-and-GitHub/Pages/git-github-setup.html",
    "title": "Pages In Progress",
    "section": "",
    "text": "Welcome! We are still working on the following pages for the workshop. Please check back in to see them!\n\n‚ÄúWhat is git and GitHub? How do they interact?‚Äù\n‚ÄúAccount set up and configuration‚Äù\nAll the references. For now, find them at the end of the slide deck!\n\n\n  \n  \n  \n  \n  \n    Men At Work - Down Under (Official HD Video) from YouTube",
    "crumbs": [
      "Getting Started with Git and GitHub",
      "Pages In Progress"
    ]
  },
  {
    "objectID": "Git-and-GitHub/Pages/git-github-overview-simple-example.html",
    "href": "Git-and-GitHub/Pages/git-github-overview-simple-example.html",
    "title": "Managing Version Control Locally",
    "section": "",
    "text": "Basics of Git/GitHub Interactions\nWhen I had to take Organic Chemistry in undergrad, my professor said that a successful student will learn why things are happening, as opposed to rote memorization. This very much applies for users of Git as well. Memorizing specific scenarios you copy-and-paste code will only get you so far with Git, as it will inevitably become a frustrating chore when things go wrong. And we‚Äôre talking about tech, we know things will go wrong at some point!\nUnfortunately, we only have enough time to introduce you to the basic structures and workflows of Git, today. I encourage you to read further about the different Git commands and especially how information is moving through the Git framework. You can start with some of the sources we‚Äôve provided earlier in the workshop (Our Choice Resources) or some of the additional sources linked to below.\nIf you are beginner with Git, be patient with yourself because this part takes time and practice, but as us Colorado skiers say ‚ÄúIf there‚Äôs no pain üéø, there‚Äôs no Jane üóª!‚Äù Let‚Äôs get to it!\nIn an established Git version-controlled environment, there are three primary domains: the Working Tree, Staged Edits, and Committed Edits. The figure below exhibits how information moves through Git‚Äôs version control and tracking framework on your local device. Notice the git * bash commands that drive the transitions between the three domains. For most scenarios, these are the Git commands you will be using.\nLet‚Äôs look at each version control domain our project files can be in:\nA configured local Git initiated project directory does not passively surveilling the remote repository‚Äôs contents. There are three core commands used to prompt your local Git to share information with the remote repository.",
    "crumbs": [
      "Getting Started with Git and GitHub",
      "Managing Version Control Locally"
    ]
  },
  {
    "objectID": "Git-and-GitHub/Pages/git-github-overview-simple-example.html#basics-of-gitgithub-interactions",
    "href": "Git-and-GitHub/Pages/git-github-overview-simple-example.html#basics-of-gitgithub-interactions",
    "title": "Managing Version Control Locally",
    "section": "",
    "text": "Figure inspired by \"What is Git commit, push, pull, log, aliases, fetch, config & clone\" by MindOrks Amit Prajapati.\n  \n\n\n\nThe Working Tree is the area where the developer makes changes to files in the project. In this domain, Git is not actively tracking changes that are made; changes get recycled back into the same file with no record of interim changes.\nWhen you are ready for Git to follow changes, you need to add them to the staged environment with git add. This prompts Git to identify differences between Staged Edits and already committed versions that are stored in the .git directory.\n\n\n\n\n\n\n\nNote\n\n\n\nYou will use the same commands even if there was no previous version of a file stored in the .git directory. When you check the version control status of your project with git status, Git will automatically identify untracked files and prompt you to add them for tracking.\n\n\n\n\n\n\n\n\nCode Like a Pro\n\n\n\n\n\nGit provides a robust framework to track changes within different files, including: storing comments explaining each change, tracing the file history, allowing recovery to older versions, and providing a line-by-line summary of changes from recent versions. Impressive!\nYet with all of this, Git doesn‚Äôt directly track file name changes. (What?!) Instead, file name changes are detected with a heuristic comparing the similarity of files committed in .git to renamed files that have been staged. This is an important distinction to be aware of because sometimes Git associates changes incorrectly.\n\n\n\n\n\n\nImportant\n\n\n\nMoving a file within the Git initiated environment is interpreted by Git as a name change.\n\n\nWhen committing a file name change, Git deletes the file listed under the old name and replaces it with a new addition of the same file under the new name. The change history of a file leading up to a name change is always retained, but the transition between name changes are not explicitly tracked as such. It is therefore best practice to commit name changes with a message clearly stating this.\nThe git mv, for move or rename, command supports clearly recording file name transitions. Example from How to rename a file in Git by Kenny DuMez:\n\n\nCommand-Line Application\n\ngit mv oldfilename.txt newfilename.txt\ngit commit -m \"Rename oldfilename.txt to newfilename.txt\"\n\n\n\n\n\nOnce you have reviewed the detected changes and approve saving and sharing them, you use git commit to promote the staged version to become the most recent copy reflected in the .git directory. It is the most recent Committed Edits that get synced over the GitHub server through a ‚Äúpeer-to-peer‚Äù patch.\n\n\n\ngit clone: establish a Git initiated project locally by downloading the entire codebase stored in a GitHub repository. With a git clone, you set the transfer protocol (SSH key or HTML url) through which information is shared and assign the ‚Äúorigin‚Äù alias to the remote location.\ngit pull: download all of the information contained in GitHub and compare it with the last checked copy of the remote repository, integrating any new changes that are not yet reflected.\ngit push: upload the most current version of your project to GitHub and integrate the new changes to the remote copy. This command is used throughout the project lifetime, and is used to establish a new remote repository in GitHub from a local, Git initiated project.",
    "crumbs": [
      "Getting Started with Git and GitHub",
      "Managing Version Control Locally"
    ]
  },
  {
    "objectID": "Git-and-GitHub/Pages/git-github-overview-simple-example.html#detailed-walk-through",
    "href": "Git-and-GitHub/Pages/git-github-overview-simple-example.html#detailed-walk-through",
    "title": "Managing Version Control Locally",
    "section": "Detailed Walk Through",
    "text": "Detailed Walk Through\n\nIdentify and Save Local Changes\nHopefully the explanations provided thus far are eliciting an aha moment for you. But if not, and you‚Äôre otherwise ready to pretend it makes perfect sense for a little longer, let‚Äôs go through an example. Later we are going to discuss version branches of your project. For now, all you need to know is we are in a Git initialized project directory and on a version controlled branch called main.\n\n  \n  \n  \n\n  \n    xkcd comic. Accessed from \"Flowing Data\" April 22nd, 2025.\n  \n\nImagine it. You have come up with what might be (and we‚Äôre scientists here so let‚Äôs not overstate) one of the best color schemes for your data ever. You generate this sweet looking, publication ready plot on the right and save the image as a file called earth_shattering_color_scheme.png. You‚Äôre now ready to record this version of your work and share it with the team through the projects GitHub (maybe even the world?), but the changes have not yet been recorded by Git.\nRECALL: The same steps are taken if this is your first image file for the plot or if you have tracked previous versions in the .git directory. For our example, it will be the former case.\nIt is always best practice to start by checking the current status of your version controlled project directory. Say that you generated this image using R in a script called making_cool_plots.R. Running git status in the command-line application will give you something like this:\n\n\n\nCommand-Line Output\n\n    On branch main\n    Your branch is up to date with 'origin/main'.\n    Changes not staged for commit:\n    (use \"git add/rm ...\" to update what will be committed)\n    (use \"git restore ...\" to discard changes in working directory)\n\n   modified:   ¬†¬† making_cool_plots.R\n   \n    Untracked files:\n    (use \"git add ...\" to include in what will be committed)\n    \n    earth_shattering_color_scheme.png\n\n\n\nThese outputs can be a little intimidating, so let‚Äôs break them down section-by-section.\n\nThe first statement is straight forward. Git is letting us know that we are interacting with it in a version controlled branch called main.\norigin/main refers to the remote GitHub repository version status of the same branch. ‚ÄúOrigin‚Äù is an alias for the remote repository location. Equivalently, we can say something like: git@github.com:ysph-dsde/PROJECT-REPOSITORY.git/main.\nThe output is telling us that our local copy of main is current with the last-checked status of the remote copy in GitHub. This means we don‚Äôt expect that there are local commits not yet reflected in the remote copy.\n\n\n\n\n\n\n\nNote\n\n\n\nYour local mirror of origin/main is not guaranteed to be a reflection of the remote repository contents in GitHub. Maybe you share the remote repository with a team who is actively pushing changes to the server, or maybe you changed a README.md, or uploaded a file directly in GitHub since you last synced your local copy. Your local Git is not passively checking the status of the remote repository, so these changes will go undetected until we tell Git to give GitHub a ring for a quick check-in.\nIt is therefore important to stipulate that origin/main in this context is the last checked status of the remote repository. Sometimes you might run into problems syncing locally committed changes with the remote repository because your local version of origin/main is not up to date.\nIt is best practice to commit file versions you want to retain to the local .git directory prior to updating your local mirror of origin/main. Later we will discuss the different commands Git uses to pass information from the remote repository to your local mirrored copy.\n\n\n\nThe next section lists version tracked files stored in the .git directory that have been changed. Git conveniently provides a few suggestions pointing to next steps: git add/rm/restore. Above, we see the color pallet changes we made in the already version controlled R script have been detected.\nThe ‚Äúuntracked files‚Äù section is where files not previously tracked by Git are listed. This means that no previously committed file versions have sufficient similarity with this file to be considered an updated version. Again, Git provides us with a suggestion on the next steps: git add.\nAs expected, this is where our newly created image file is listed.\n\nUp until this point, file iterations and changes are not recorded in Git‚Äôs version history. Before we can store a snapshot of these edits, we need to first add them to the Staged Edits domain. This is done by using the Git command git add in one of two ways:\n\nExplicitly list out each file you want to add to Staged Edits OR\nUse the ‚Äúwild card‚Äù, ., to add every file listed under the git status output.\n\n\n\nCommand-Line Application\n\n# OPTION #1: List each file\ngit add \"making_cool_plots.R\" \"earth_shattering_color_scheme.png\"\n\n# OPTION #2: Use the wild card \".\" to add all files\ngit add .\n\n# View the results of git add.\ngit status\n\n\nCommand-Line Output\n\n    On branch main\n    Your branch is up to date with 'origin/main'.\n    \n    Changes to be committed:\n    (use \"git restore --staged ...\" to unstage)\n\n   modified:   ¬†¬† making_cool_plots.R\n   new file: ¬†¬† earth_shattering_color_scheme.png\n    \n\n\nThe files have now been moved from the Working Tree to the Staged Edits domain. Notice that this domain is not applying any changes to your project directory. Merely, the stage is a buffer between pending changes and the codified version history of the projects contents. All files promoted for saving get packaged with a message explaining the reason for the version update.\n\n\n\n\n\n\nCode Like a Pro\n\n\n\nAstute students will notice that staging edits allows the opportunity to group like changes to one commit action. This is a highly advantageous feature that allows you to better control how version changes are recorded in .git. Doing so improves bug troubleshooting and minimizes collateral changes a revert might cause on unrelated parts of the project.\n\n\nIn our example, the two files we have staged are related and the changes we made are objectively flawless, so let‚Äôs proceed with committing the changes using git commit. Notice that a message is required with every commit action. It is easiest to add the message inline:\ngit commit -m \"Revelatory message elucidating the hidden secrets of git.\"\nBecause the message is a mandatory element of a commit action, if you forget to include one Git will always be there to forcibly remind you by opening an editor where you can include one. Thank you so much, Git. If you have not specified the editor Git will use in such circumstances, then it will open up the default vi editor.\nTo show you how to navigate this outcome, we‚Äôre going to forget to include our message.\n\n\nCommand-Line Application\n\ngit commit\n\n\n\n\nCommand-Line Output\n\n    \n\n    \n    # Please enter the commit message for your changes. Lines starting\n    # with '#' will be ignored, and an empty message aborts the commit.\"\n    #\n    # On branch main\n    # Your branch is ahead of 'origin/main' by 1 commit.\n    # (use \"git push\" to publish your local commits)\n    #\n    # Changes to be committed:\n    # modified:   ¬†¬† making_cool_plots.R\n    # new file: ¬†¬† earth_shattering_color_scheme.png\n    \n    \n\n\nAfter entering git commit without a message, Git automatically opens a vi window inside the command-line application. There are specific commands that you will need to use inside this application, some of which can be found here: ‚ÄúAn introduction to the vi editor‚Äù by Ken Hess.\nTo add a message you need to do the following steps:\n\nWhen the vi window first opens it is in ‚Äúcommand‚Äù mode. Hit either a or i on your keyboard to enter ‚Äúinsert‚Äù mode. When you do this, you might see -- INSERT -- at the bottom of the application window.\nAdd in your message in the line at the top of the document. Do NOT include a # in front, as this will cause your message to be ignored.\nHit Esc to exit ‚Äúinsert‚Äù mode and reenter ‚Äúcommand‚Äù mode.\nSave progress typing :w and hitting enter. If you are ready to exit vi then you save and exit using :wq instead. NOTE: :w/:wq will show up at the bottom of the application window.\n\nFor our example, after I entered ‚Äúinsert‚Äù mode by typing a on the keyboard, I add the message ‚ÄúOutstanding progress on color schemes for density plot fill scaling.‚Äù I then save and exit vi by hitting Esc then typing :wq and hitting enter.\n\nCommand-Line Output\n\n\n    Outstanding progress on color schemes for density plot fill scaling.\n    # Please enter the commit message for your changes. Lines starting\n    # with '#' will be ignored, and an empty message aborts the commit.\"\n    #\n    # On branch main\n    # Your branch is ahead of 'origin/main' by 1 commit.\n    # (use \"git push\" to publish your local commits)\n    #\n    # Changes to be committed:\n    # modified:   ¬†¬† making_cool_plots.R\n    # new file: ¬†¬† earth_shattering_color_scheme.png\n    :wq\n    \n    \n\n\n\nCommand-Line Output\n\n\n    [main f9b4cf2] Outstanding progress on color schemes for density plot \n    fill scaling.\n    2 files changed, 11 insertions (+), 2 deletions (-)\n    create mode 100644 earth_shattering_color_scheme.png\n    \n\n\nSuccessfully committing our staged edits to the .git directory gives the second output shown. Here, Git is affirming that we have associated the message ‚ÄúOutstanding progress on color schemes for density plot fill scaling.‚Äù to the commit hash ID f9b4cf2 in the branch main version history.\nIt then summarizes the total number of files changed, the total number of line insertions and deletions tallied, and finally it will summarize the file mode. In our example, we have edited two files which have a total of 11 line insertions and deletions between them. The newly created file is associated with directory object type, 100, and attributes the writeable permissions, 644. Together, mode 100644 means earth_shattering_color_scheme.png will be a ‚Äúregular‚Äù file with ‚Äúnon-executable group-writeable‚Äù permissions (StackExchange reply by Go Dan).\n\n\n\n\n\n\nCode Like a Pro\n\n\n\nThe commit ID is randomly assigned to any newly created version that has been successfully added to the .git directory. It is the same ID that will show up on GitHub to identify distinct versions and their parents, and it constitutes the first alphanumeric characters used in the 40 character SHA-1 checksum associated with the commit. Executing a git log will show the version history progression for the currently checkout branch, and will provide the entire SHA-1 checksum.\nRead more in Atlassian‚Äôs Advanced Git log.\n\n\nWe are now well on our way to sharing our updates with the remote repository.\n\n\nPreamble to Sharing Changes with GitHub\nIn the series of detailed command-line outputs presented above, there were a few key status cues that indicate the projects version status relative to the remote repository. These cues are summarized in the flow diagram below. Recall that origin/main denote the remote copy of the project branch main housed in GitHub. More accurately, it is the last checked state of origin/main.\n\n  \n\n  \n    Indicators of the projects local mirror's status relative to the copy housed in the GitHub remote repository.\n  \n\nSpecifically take notice of the cue provided in the second box. Here, Git is telling us that our local copy of the branch main is ahead of the remote copy by one commit. Remember that changes made to files in the Working Tree go unnoticed by Git, and the committed changes are what get evaluated for version control management.\nWhat this prompt means is we have taken one step away from the cohesive version where Git recognized our local copy of the project to be the same as the remote copy. Subsequently committed versions will automatically inherit the history of the parent version along with the newly included modifications in a linear fashion. If we had instead changed three different aspects of the project, and committed these three like changes together in separate commit actions, then this message will say that we are three commits ahead.\n\n\nPull Before You Push\nBefore we update the remote copy of our branch main to reflect our changes with git push, it is good practice to review updates that might have occurred in the remote repository since we last prompted Git to access it. This is done with an action called git pull. There are two possible situations you can run into after executing a git pull at this stage of the process:\n\nNo changes have been made to origin/main, justifying no change to your local copy with git pull.\nChanges have been made to origin/main, requiring reconciliation of the divergent versions.\n\nThe first case is straightforward, and so we will only discuss two methods available to reconciling the second case. Consider the diagram below showing an example divergent commit history of the local branch main from its remote copy.\n\n\n\n\n\n\n\n  \n  \n  \n\n  \n    All three diagrams used here are from Atlassian's \"Git Tutorials\". Downloaded April 24th, 2025.\n  \n\n\n\nIn purple, we have the version of origin/main retained on our local device from which we have been working. This is the version of origin/main that our local Git uses to reference changes made in the same branch, represented in blue with the commits E-F-G. In green are additional changes made directly in GitHub or from another collaborator that have been integrated into origin/main with the commits A-B-C.\n\n\n\n\n\n\n\n\n\nCode Like a Pro\n\n\n\n\n\nThere are a great deal of commands associated with Git‚Äôs version control framework. It is most helpful to slowly expand your Git vocabulary and tool box by exploring related commands, or commands that specifically address your workflow needs. Below are a couple of good places to start advancing your basic understanding of Git:\n\ngit log facilitates navigating the version history of your project. This command is most often used to understand version differences prior to merging or rebasing, such as following a git fetch. Read more from Atlassian‚Äôs Git Tutorial: ‚ÄúAdvanced Git log‚Äù.\nAtlassian‚Äôs comment on: Merging vs.¬†Rebasing, specifically the section about the golden rule for rebasing.\n\n\n\n\nIn actuality, git pull is two Git actions wrapped into one command: git fetch and one of two integration protocols, git merge or git rebase. git fetch will download the files and version history currently reflected in the remote copy of origin/main as a temporary branch by the same name on your local device (read more from Atlassian‚Äôs Git Tutorial: Git fetch). In the diagrams below, we see the different ways git merge and git rebase will interpret a coalescence of the two.\n\n\n\n\n\n\nMerge\n\n  \n  \n  \n\n\n\nRebase\n\n  \n  \n  \n\n\n\n\ngit merge conducts a three way commit: two inherited from the heads of each branch (versions C and G) and a third for the merge action that creates a new version that integrates changes relfected in C and G, here called H. git rebase will realign the commit histories of the two branches relative to one another by pasting the series of one branch at the head of the other. Doing this necessitates redefining the parent commit history for the newly appended commit series, from which we get the name ‚Äúrebasing‚Äù. The figure above shows rebasing the main branch commits with origin/main A-B-C, creating the rebased versions of those commits, E‚Äô-F‚Äô-G‚Äô.\n\n\nCommand-Line Application\n\n# -----------\n# Pull with one command.\n\n# OPTION #1: Integrate the fetched copy of \"origin/main\" into \"main\" with merge.\ngit pull                        # Assuming the default protocol is a merge\n\n# OPTION #2: Rebases \"main\" with the new parent history reflected in \"origin/main\".\ngit pull --rebase               # Override the default merge to do a rebase\n\n\n\nCommand-Line Application\n\n# -----------\n# Two-step pull.\n\n# Download branch main from the remote repository, origin.\ngit fetch origin main\n\n# If needed, return to the local copy of main, not the fetched branch.\ngit checkout main\n\n# OPTION #1: Integrate the fetched copy of \"origin/main\" into \"main\" with merge.\ngit merge FETCH_HEAD\n\n# OPTION #2: Rebases \"main\" with the new parent history reflected in \"origin/main\".\ngit rebase FETCH_HEAD\n\n# If needed, remove the fetched copy of \"origin/main\" saved as a branch.\ngit branch -d FETCH_HEAD\n\nIf you are new to Git and uncomfortable discerning when to use one option over the other, it is best to employ a git merge. Fortunately, this is the default protocol used by git pull! Regardless of your comfort level with Git, it is important to understand the different protocols and that there are times when one is better to use over the other.\n\n\n\n\n\n\nImportant\n\n\n\nThe complete and current copy of your project is typically stored in the remote repository in the branch origin/main, where the development team or the public can access it. In development workflows, the publicly facing copy is treated as the current baseline on which further developments needs to based one.\nIf you decide to try git rebase, it is best practice to never rebase the remote copy of origin/main for this reason. Instead, only rebase your local branches with the remote version.\n\n\nIn general, use git merge when:\n\nyou are new to Git or not comfortable using a rebase.\nyou have longer periods over which you develop features that rarely get merged into the main workflow.\nyou use git merge all the time for no reason, but also happen to be a wiz at using git log (and can possibly visualize in the fourth dimension), making sorting through the pile of commits a trivial task.\n\nUse git rebase when:\n\nyou want to avoid over complicating the version history by keeping it linear.\nyou want to update your base with the teams current base reference in GitHub.\nyou are not adding many version tracked edits to a branch before coalescing them again.\nyou are a meticulous and neat Git user, frequently committing your work in well messaged packages, limiting the possibility of wreaking havoc on the commit history with a rebase.\n\n\n\n\n\n\n\nNote\n\n\n\nNotwithstanding conflicts between the branches, git merge is considered to be a non-destructive, but non-linear, way of integrating two version histories. git rebase, on the other hand, maintains a linear version history but can be destructive to the commit history or create complicated divergences that are harder to bring together if used improperly.\nWhen choosing your coalescing method, consider the position of your branch relative to the completely integrated copy of the project and the number of version tracked commits that differ between the branches.\n\n\n\n\nTime to Share with the World\nWhew! We‚Äôve covered quite a bit of ground. To summarize, we have grouped similar project edits in one commit with a message explaining our work, advancing our projects .git directory one step forward. After committing all the changes in our repository, we prompted Git to check the status of origin/main stored in GitHub, and discussed two different coalescing strategies offered by git pull: git merge and git rebase.\nWe are now prepared to update the remote repository with git push. Recall the figure above that summarizes key status cues:\n\n  \n\n  \n    Indicators of the projects local mirror's status relative to the copy housed in the GitHub remote repository.\n  \n\nPushing our changes to GitHub will cause the commit HEAD of our local copy of branch main to merge with the same branch stored in the remote repository. HEAD is a term describing the latest commits available in the .git directory for that checked-out branch. Sometimes, you might see it referred to as main --&gt; main instead.\n\n\nCommand-Line Application\n\ngit push origin main\n\n\nCommand-Line Output\n\n\n    Enumerating objects: 14, done. \n    Counting objects: 100% (14/14), done.\n    Delta compression using up to 8 threads\n    Compressing objects: 100% (9/9), done.\n    Writing objects: 100% (9/9), 90.13 KiB | 22.53 MiB/s, done.\n    Total 9 (delta 5), reused 0 (delta 0), pack-reused 0 (from 0)\n    remote: Resolving deltas: 100% (5/5), completed with 5 local objects.\n    To github.com:ysph-dsde/OUR-PROJECT.git\n    7d1b339..f9b4cf2  main -&gt; main\n    \n\n\nThe git push output will look something like this. It indicates that our upload was completed successfully, and supplies some details about the update. For example, it gives the previously committed versions ID, which is now updated from 7d1b339 to f9b4cf2, the remote repository location, and the size of the objects we wrote to the remote repository.\nCongratulations! You have completed the in-depth walk through exhibiting standard Git mediated project version control and Git/GitHub interactions!",
    "crumbs": [
      "Getting Started with Git and GitHub",
      "Managing Version Control Locally"
    ]
  },
  {
    "objectID": "Data-Visualization-with-ggplot2/index.html",
    "href": "Data-Visualization-with-ggplot2/index.html",
    "title": "Data Visualization with ggplot2",
    "section": "",
    "text": "Introduction\nIn this workshop we delve deeper into the domain specific language of statistical graphics that underpins the tidyverse ggplot2 package syntax: the ‚ÄúGrammar of Graphics‚Äù. We will explore each discrete grammar layer using laboratory-confirmed RSV hospitalizations data collected by the CDC‚Äôs Respiratory Virus Hospitalization Surveillance Network (RESP-NET) surveillance program.\nWith a better understanding of the syntax fundamentals, we will then get introduced to some advanced uses of ggplot2 that are commonly used in public health:\nWe will close the workshop by asking Yale‚Äôs Clarity Platform to reproduce our code from the plot image alone to exhibit how AI can be used to support data visualization work. Clarity is an AI chatbot that offers similar functions to OpenAI‚Äôs ChatGPT and Microsoft Copilot with additional data protection. Find out more about Clarity‚Äôs security guidelines on ‚ÄúAI at Yale‚Äù.\nThe cleaned and harmonized version of the RSV-NET dataset was compiled as part of the YSPH‚Äôs very own PopHIVE project. Special thanks to Professor Daniel Weinberger for allow us to adopt his plot code in this workshop.",
    "crumbs": [
      "Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "Data-Visualization-with-ggplot2/index.html#introduction",
    "href": "Data-Visualization-with-ggplot2/index.html#introduction",
    "title": "Data Visualization with ggplot2",
    "section": "",
    "text": "Making plots interactive with plotly\nProjecting data to a map",
    "crumbs": [
      "Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "Data-Visualization-with-ggplot2/index.html#accessing-the-materials",
    "href": "Data-Visualization-with-ggplot2/index.html#accessing-the-materials",
    "title": "Data Visualization with ggplot2",
    "section": "Accessing the Materials",
    "text": "Accessing the Materials\n\nSlides, Handouts, and Other Materials\nDownload the complete slide deck with annotations and the in-person workshop handout. Comments were saved in the bottom left of each slide, and references for this webpage are in its Appendix.\n\n\nCodespaces\nIn this workshop you will need to access the R code we have prepared for the in-workshop discussion and after-workshop challenge questions. This assumes that you have downloaded R and RStudio to your local device. After you download the code, you will need to:\n\nMove the unzipped directory to the file location you wish to house the project.\nOpen Data-Visualization-with-ggplot2.Rproj.\nOpen Discussion and Challenge Questions.R.\nInitialize the environment in the R console by running:\nrenv::init()               # initialize the project\nrenv::restore()            # download packages and their version saved in the lockfile.\n\nNOTE: If you are asked to update packages, say no. The renv() is intended to recreate the same environment under which the project was created, making it reproducible. You are ready to proceed when running renv::restore() gives the output:\n- The library is already synchronized with the lockfile.\nYou can read more about renv() in their vignette. In this workshop you will need to access the R code we have prepared for the worked through example and challenge questions. If you have not already, you will need to download R to your local device, and we suggest using the integrated development environment (IDE) software RStudio. Accessing the code for this workshop requires that you have git installed on your local device, a GitHub account, and you have configured the two. If you have not done this, go through Accounts and Configurations first.\n\n\n\n\n\n\nImportant\n\n\n\n\n\nThis workshop was generated using R (v 4.4.3) in the RStudio IDE (v 2024.12.1+563). renv() is included to reproduce the same coding enviroment, storing all the relevant packages and package versions needed in the code. If you experience trouble running the scripts, you might want to check that the environment was initialized and that you are using the same version of R and RStudio.\n\n\n\n\n\nInitializing the Environment\nAfter cloning the codespace to your local device, you will need to initialize the environment using renv(). This will install all packages and versions used in the workshop, thus creating a reproducible coding environemnt.\n\nIn the command-line application (i.e.¬†Terminal for Macs and Windows Terminal for windows) navigate to the file location you want to store the repository.\ncd \"/file_location/\"\nLaunch the project by opening the *.Rproj in RStudio.\nIn the R console, activate the enviroment by runing the following lines of code:\nrenv::init()          # initialize the project\nrenv::restore()       # download packages and their version saved in the lockfile.\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are asked to update packages, say no. The renv() is intended to recreate the same environment under which the project was created, making it reproducible. You are ready to proceed when running renv::restore() gives the output:\n- The library is already synchronized with the lockfile.\nIf you experience any trouble with this step, you might want to confirm that you are using R (v 4.4.3) in the RStudio IDE (v 2024.12.1+563). You can also read more about renv() in their vignette.",
    "crumbs": [
      "Data Visualization with ggplot2"
    ]
  },
  {
    "objectID": "Data-Visualization-with-ggplot2/Pages/visualization-more-to-come.html",
    "href": "Data-Visualization-with-ggplot2/Pages/visualization-more-to-come.html",
    "title": "Pages In Progress",
    "section": "",
    "text": "Welcome! We are still working on the following pages for the workshop. Please check back in to see them!\n\n‚ÄúBrief history on data visualization‚Äù\n‚ÄúChallenge questions with solutions‚Äù\nAll the references. For now, find them at the end of the slide deck!\n\n\n  \n  \n  \n  \n  \n    Men At Work - Down Under (Official HD Video) from YouTube",
    "crumbs": [
      "Data Visualization with ggplot2",
      "Pages In Progress"
    ]
  },
  {
    "objectID": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html",
    "href": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html",
    "title": "Worked Through Example",
    "section": "",
    "text": "Environment Set-Up and Data Description\nFirst, we will load the necessary libraries and any special functions used in the script.\n# NOTE: renv initializing might need to be run twice after the repo is\n#       first copied.\n#renv::init()\nrenv::restore()\n\nsuppressPackageStartupMessages({\n  library(\"arrow\")         # For reading in the data\n  library(\"dplyr\")         # For data manipulation\n  library(\"ggplot2\")       # For creating static visualizations\n  library(\"plotly\")        # For interactive plots\n  library(\"cowplot\")       # ggplot add on for composing figures\n  library(\"tigris\")        # Imports TIGER/Line shapefiles from the Census Bureau\n  library(\"sf\")            # Handles \"Special Features\": spatial vector data\n  library(\"RColorBrewer\")  # Load Color Brewer color palettes\n  library(\"viridis\")       # Load the Viridis color pallet\n})\n\n# Function to select \"Not In\"\n'%!in%' &lt;- function(x,y)!('%in%'(x,y))\nNow we will import our cleaned and tidy data, which is ready for plotting. Students who would like to find out more about how to get their data into the plottable, tabular form you will see here can explore our A Journey into the World of tidyverse workshop.\ndf &lt;- read_parquet(file.path(dirname(getwd()), \"Data/RSV-NET Infections.gz.parquet\"))\n\n# glimpse() allows us to see the dimensions of the dataset, column names,\n# the first few entries, and the vector class in one view.\ndf |&gt; glimpse()\n\nRows: 92,519\nColumns: 14\n$ Region                  &lt;chr&gt; \"California\", \"California\", \"California\", \"Cal‚Ä¶\n$ Season                  &lt;chr&gt; \"2018-19\", \"2018-19\", \"2018-19\", \"2018-19\", \"2‚Ä¶\n$ `Week Observed`         &lt;date&gt; 2018-10-06, 2018-10-13, 2018-10-20, 2018-10-2‚Ä¶\n$ MMWRyear                &lt;dbl&gt; 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018‚Ä¶\n$ MMWRweek                &lt;dbl&gt; 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25‚Ä¶\n$ MMWRday                 &lt;dbl&gt; 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7‚Ä¶\n$ Characteristic          &lt;chr&gt; \"Age\", \"Age\", \"Age\", \"Age\", \"Age\", \"Age\", \"Age‚Ä¶\n$ Level                   &lt;chr&gt; \"1-4 Years\", \"1-4 Years\", \"1-4 Years\", \"1-4 Ye‚Ä¶\n$ `Positives Detected`    &lt;dbl&gt; 0, 0, 3, 10, 8, 8, 3, 6, 8, 15, 15, 25, 23, 22‚Ä¶\n$ `Scaled Positives`      &lt;dbl&gt; 0.000000, 0.000000, 3.896104, 12.987013, 10.38‚Ä¶\n$ Spline                  &lt;dbl&gt; 0.000000, 2.184079, 5.738394, 8.770741, 9.5923‚Ä¶\n$ Kernel                  &lt;dbl&gt; 0.000000, 2.897880, 6.721988, 9.740228, 10.945‚Ä¶\n$ `Crude Rate`            &lt;dbl&gt; 0.0, 0.0, 0.6, 2.5, 1.9, 1.9, 0.6, 1.3, 1.9, 3‚Ä¶\n$ `Cumulative Crude Rate` &lt;dbl&gt; 0.0, 0.0, 0.6, 3.1, 5.0, 6.9, 7.6, 8.8, 10.7, ‚Ä¶\nThis workshop uses the Center for Disease Control‚Äôs (CDC) Respiratory Syncytial Virus Hospitalization Surveillance Network (RSV-NET) surveillance data. It is one of the CDC‚Äôs Respiratory Virus Hospitalization Surveillance Network (RESP-NET) Emerging Infections Programs (EIP). This version was downloaded from data.gov in January of 2025.\nRSV-NET conducts active, population-based surveillance for laboratory-confirmed RSV-associated hospitalizations. It contains stratification for geolocation, race/ethnicity, age, and sex. The cleaned and harmonized version of the RSV-NET dataset was compiled as part of the YSPH‚Äôs very own PopHIVE project. You will see that its contents differ slightly from what you would see on the data.gov website.\nDescription of the variables:",
    "crumbs": [
      "Data Visualization with ggplot2",
      "Worked Through Example"
    ]
  },
  {
    "objectID": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html#environment-set-up-and-data-description",
    "href": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html#environment-set-up-and-data-description",
    "title": "Worked Through Example",
    "section": "",
    "text": "Code Like a Pro\n\n\n\nOur data was stored as a parquet file. Para-what? Parquet is a column-oriented data file that allows for efficient data storage and lightweight information retrieval. It is best suited for large data sets that cannot be easily handled ‚Äúin-memory‚Äù. Using the arrow package, we can read and manipulate files in this form.\nThose interested to learn more about how they can use parquet to efficiently process large datasets are encouraged to review the workshops hosted by one of our guest speakers, Professor Thomas Lumley: Thomas Lumley Workshops.\n\n\n\n\n\n\n\nRegion - geolocation at the state and 10 Health and Human Services Regions (HHS) level.\nSeason - the infection season of the observation, defined to span from July to June of the following year.\nWeek Observed - the week when the record was added, in Date format.\nMMWRyear, MMWRweek, MMWRday - the year, week, and day of the entry in Morbidity and Mortality Weekly Report (MMWR) format. MMWR is the standard epidemiological week assigned by National Notifiable Diseases Surveillance System (NNDSS) in their disease reports (MMWR Definition).\nCharacteristic and Level - the type of additional stratification and the group represented, respectively. i.e.¬†‚ÄúCharacteristic = Sex; Level = Female‚Äù.\nPositives Detected - the number of lab-confirmed RSV hospitalizations detected.\nScaled Detected - the relative scale of RSV infections detected for inter-season comparison, controlling for each stratification. Outcomes were grouped by Region and Level then scaled using \\text{Positives Detected}/max(\\text{Positives Detected})*100.\nSpline - smooth.spline(MMWRweek, Scaled Positives) from the stats package. Parameters were automatically optimized by the algorithm as this is only for smoothing the trendline.\nKernel - locfit(Scaled Positives ~ lp(MMWRweek, nn = 0.3, h = 0.05, deg = 2)) from the locfit package. No rigorous method was applied to optimize parameters as this is only for smoothing the trendline.\nCrude Rate - the number of residents in a surveillance area who are hospitalized with laboratory-confirmed RSV infections divided by the total population estimated for that area per 100,000 persons.\nCumulative Crude Rate - the crude rate added cumulatively over the course of one infection season.",
    "crumbs": [
      "Data Visualization with ggplot2",
      "Worked Through Example"
    ]
  },
  {
    "objectID": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html#basic-uses-of-ggplot2",
    "href": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html#basic-uses-of-ggplot2",
    "title": "Worked Through Example",
    "section": "Basic Uses of ggplot2()",
    "text": "Basic Uses of ggplot2()\n\n\n\n\nFigure from ‚Äúggplot2 workshop part 1‚Äù by Thomas LinPedersen. Accessed from YouTube March 15th, 2025.\n\n\n\n\nThe Data and Mapping Layers\nThe first (and arguably most crucial!) layer is Data, but simply adding it to ggplot() will only generate a plot object with nothing else. In the second layer, Mapping, we tell the function which variables get used for which aesthetic feature displayable on the plot object.\nIn this layer, we define the position, color, size, or shape that our values take. Every type of data representation requires an aesthetic statement to point variables to relevant aesthetic features. This can help make a plot visually appealing, but an astute user of ggplot() will leverage them to highlight underlying patterns in the data as well.\nHere we use the mapping function, aes(), to point the week in the epidemiological year (MMWR) variable to the x-axis and RSV positive tests (scaled and Gaussian kernel smoothed) to the y-axis.\n\n\n\n\n\n\nGeometry and Statistic Layers Dictate the Aesthetics Mapping\n\n\n\nAs we will see in the next two layers, the kinds of features that are required to generate the most fundamental visualization of our data will depend on the type of geometry or statistical transformation we are plotting. Data and Mapping must always be defined by the user. Some geom_*() or stat_*() functions also require the plot-specific statistic or position to be provided by the user, but sometimes these elements are already assigned by the default settings.\nYou can find more about the required and ancillary aesthetic features used by different Geometry or Statistics layers in the ggplot2 package references documentation and cheatsheet. Different specifications available for aesthetic features can also be found in one of their vignettes: aesthetic specifications.\n\n\n\n# The data and aesthetics mapping layers combined.\nggplot(data = df, aes(x = MMWRweek, y = Kernel))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWe can use the base R pipe symbol |&gt; to pass objects into subsequent functions that build on the previous result. This has the added benefit of organizing operations into digestible pieces, as opposed to gnarly nested functions. That would not be so knarly, man!\nGoing forward we will no longer explicitly dictate that data = df, as this is already implied by the pipe operation. Just keep in mind that the start of a graphical expression begins with a ggplot() + statement, and everything preceding this is not part of the graphical layers.\n\n\n\n\nThe Geometry Layer\nWe will now tell the function how we want the data to be displayed in the plot object. We do this by adding the Geometry layer. Together with Data and Mapping, these three layers form the core pieces required to generate any basic visualization with ggplot2.\nThe Geometry layer does the computational legwork that translate a data frame with mappings into a discernible plot. Behind the scenes, it is computing how points get spaced and oriented to create the specific geometry defined, whether that be for a histogram, scatter plot, box plot, and so forth.\nEach geometry layer can take a specific data and aesthetics mapping, overwriting anything defined in the ggplot() plot object. It also interprets a statistical transformation and position adjustment to modulate the graph. Here, we will plot a trend line showing changes in RSV positives detected over the course of an infection season by using geom_line().\n\n\n\n\n\n\nNote\n\n\n\nIn some ggplot2 references statistics and position are both defined as separate layers in the hierarchy. This workshop separates out statistics, but does not separate out position its own layer.\nPosition sets the rules around how objects get placed relative to one another; a setting necessary within some geom_* functions. Think of plotting a histogram scaled with an aesthetic color mapping. Do the groupings plot on top of each other, side-by-side, or get scaled to fill [0, 1] on the y-axis? This is what the position setting will determine.\n\n\n\n# All three required layers combined: data, aesthetics mapping, and geometry.\ndf |&gt;\n  ggplot() +\n    geom_line(aes(x = MMWRweek, y = Kernel))\n\n\n\n\n\n\n\n\nLook at this plot, I mean oy vey! If we think back to the glimpse of our dataset we might remember that there are additional columns of information that we can use to further distinguish one infections trend.\n\n\n$Region\n [1] \"California\"     \"Colorado\"       \"Connecticut\"    \"Georgia\"       \n [5] \"Maryland\"       \"Michigan\"       \"Minnesota\"      \"New Mexico\"    \n [9] \"New York\"       \"North Carolina\" \"Oregon\"         \"Region 1\"      \n[13] \"Region 10\"      \"Region 2\"       \"Region 3\"       \"Region 4\"      \n[17] \"Region 5\"       \"Region 6\"       \"Region 8\"       \"Region 9\"      \n[21] \"Tennessee\"      \"Utah\"          \n\n$Season\n[1] \"2016-17\" \"2017-18\" \"2018-19\" \"2019-20\" \"2020-21\" \"2021-22\" \"2022-23\"\n[8] \"2023-24\" \"2024-25\"\n\n$`Characteristic Level`\n [1] \"1-4 Years\"                        \"18-49 Years\"                     \n [3] \"5-17 Years\"                       \"50-64 Years\"                     \n [5] \"65-74 Years\"                      \"75+ Years\"                       \n [7] \"&lt;1 Years\"                         \"American Indian or Alaska Native\"\n [9] \"Asian or Pacific Islander\"        \"Black or African American\"       \n[11] \"Female\"                           \"Hispanic or Latino\"              \n[13] \"Male\"                             \"N/A\"                             \n[15] \"White\"                           \n\n\n\ndf |&gt;\n  # Subset the data to one infection trend outcome by selecting one possible\n  # instantiation from the array of distinguishing variables.\n  filter(Region == \"Connecticut\", Season == \"2021-22\", Level == \"N/A\") |&gt;\n  ggplot() +\n    geom_line(aes(x = MMWRweek, y = Kernel))\n\n\n\n\n\n\n\n\nThis looks much nicer, but it doesn‚Äôt tell us much about our data. Notice, however, that the same plot can be generated by adding the aesthetics mapping to the plot object (ggplot()) or the geom_*() layer.\n\n# A viable alternative representation of the above code:\ndf |&gt;\n  filter(Region == \"Connecticut\", Season == \"2021-22\", Level == \"N/A\") |&gt;\n  ggplot(aes(x = MMWRweek, y = Kernel)) +\n    geom_line()\n\nDiscussion: Can you think of reasons why you would choose one over the other?\nYou might be asking yourself why I went through the pains of showing the thought process behind tuning the plot so that it shows one distinguishable trend line. Am I not simply covering the grammar of whatever to plot a simple trend line while you eat a delicious cookie and compartmentalize your upcoming exams?\nAs I hinted at earlier, the advanced user of ggplot2 is going to leverage these layers for effective visualization of underlying patterns of the data itself. By controlling for variables that add noise or redundancies to a plot, we are opening the door for inspiring communicating insights through visualization.\nRecall:\n\n‚Äú‚Ä¶ graphics are instruments of reasoning about quantitative information‚Äù ‚Äì Yale Professor Edward Tufte from his book The Visual Display of Quantitative Information\n\nMore on this in a moment. But while I have your attention, those cookies are delicious; this is objectively and observably true.\n\n\nThe Statistics Layer\nFollowing the Geometries layer in our hierarchy is Statistics. In this context, statistics refers to the transformations applied to data primarily for the purposes of generating plottable values. For example, calculating box plot quartiles or bar plot counts.\nThese same transformations are being used under the hood of the geome_*() functions. As you might expect, many statistics functions are interchangeable with geometric functions. For example, one can use geom_bar(stat = \"count\") or stat_count(geom = \"bar\") to produce the same bar plot (ggplot2 Layer statistical transformations - Paired geoms and stats).\nKeep in mind, however, that this is not always true, and sometimes statistical functions are sub-components of composite geometric engines. One example being the stat_ydensity() function, which generates the smoothed lines along the y-axis of a violin plot.\n\n\n\n\n\n\nImportant\n\n\n\nIf you want to use a statistically transformed variable for an aesthetic like fill or color, you need to use after_stat() around the variable name to scale the mapped aesthetic properly. An example provided in the ggplot2 cheatsheet is: ggplot(df) + stat_density_2d(aes(fill = after_stat(level)), geom = \"polygon\").\n\n\nIn our example I had separately smoothed the ‚ÄúScaled Positives‚Äù variable using a spline or Gaussian kernel. If I plot a ggplot2 statistic layer that smooths the same variable using the locally estimated scatter plot smoothing (LOESS) method we see it aligns closely with the Gaussian kernel result.\n\ndf |&gt;\n  filter(Region == \"Connecticut\", Season == \"2021-22\", Level == \"N/A\") |&gt;\n  ggplot() +\n    # Values smoothed before plotting using Gaussian kernel.\n    # Plotted as the black line.\n    geom_line(aes(x = MMWRweek, y = Kernel)) +\n    # Values smoothed by the stat_smooth() ggplot function using LOESS.\n    # Plotted as the blue line.\n    stat_smooth(aes(x = MMWRweek, y = `Scaled Positives`),\n                geom = \"smooth\", method = \"loess\",\n                se = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode Like a Pro\n\n\n\nWhen a stat_*() is applied to a data frame (either inside a Geometric or Statistic layer), a modified data frame is generated as the output containing new, transformed variables. It is possible to call these ‚Äúgenerated variables‚Äù within the plot object and use them for graph tuning.\nOne example provided in ggplot2: Elegant Graphics for Data Analysis, shows how to call the stat_density() ‚Äúgenerated variable‚Äù, density, created when the data frame is passed through geom_histogram(): Chapter 13 Generated variables.\n\nggplot(df, aes(x)) + geom_histogram(binwidth = 500) plots a histogram with counts as the y-axis.\nggplot(df, aes(x)) + geom_histogram(aes(y = after_stat(density)), binwidth = 500) plots that same histogram with the calculated distribution density as the y-axis.\n\n\n\n\n\nThe Scales Layer\nIn the same way the Statistics layer defines the statistical transformations happening under the hood of the geometric functions, Scales is what interprets an aesthetic Mapping into plottable values. Once the aesthetics are defined by the user, the ggplot2 algorithm automatically applies the necessary scales. Unless we want to customize the scaling, the user does not need to explicitly write out the default scales needed to generate a plot.\nFor example, scale_*_continuous() gets automatically applied to our plot because of the x and y aesthetics mappings we‚Äôve defined. The code snippet below explicitly writes out these scaling functions that get used, but because we are not modifying their defaults it is not necessary to include them in our own code.\n\n# The automatically applied scale_*() functions to the x and y mapping.\ndf |&gt;\n  filter(Region == \"Connecticut\", Season == \"2021-22\", Level == \"N/A\") |&gt;\n  ggplot(aes(x = MMWRweek, y = Kernel)) +\n    geom_line() +\n    # The following two lines are not required for us to include since\n    # they are implied by the type of x and y vectors we assigned.\n    scale_x_continuous() +\n    scale_y_continuous()\n\nOne of the greatest advantages to ggplot2 is it offers users a great deal of flexibility. This concept is especially true for the Scales layer. While the preceding layers offer some level of customization, the Scales layer increases the available options by adding on top of previous settings. This cross-layer communication makes for a seemingly endless array of options and can make it one of the hardest layers to master.\nMost customization options fall into two buckets:\n\nPosition scales and axes (Chapter 10 of ggplot2: Elegant Graphics for Data Analysis)\nColor scales and legends (Chapter 11 of the same book)\n\nThe different applications of Scales covered in these chapters range from canonical axes scaling using scale_*_log10(), scale_*_sqrt(), and scale_*_reverse() to tuning axis breaks and labeling or from scaling color pallets to cleaning the legend. The two chapters I‚Äôve cited here from ggplot2: Elegant Graphics for Data Analysis by Hadley Wickham, Danielle Navarro and Thomas Lin Pedersen are invaluable introductions to different applications of Scales.\nIn the Scales layer of our example, we will use labs() to customize the plot labels and set the y-axis limits to span the entire range of our variable, [0, 100]. It is also possible to assign customized color pallets to grouped outcomes. Say that for our example we want to compare RSV infection trends between seasons going back three years to 2022, including the current infections season. How do we modify our running plot example to do this?\nSteps:\n\nAdd an aesthetic Mapping that prompts the plot object to group the unique seasons represented and associate them with a color.\nAdd a scale_color_* function that will apply a customized color to the Scales layer instead of the default palette.\n\n\n# Specify the infection seasons we'd like to see out of the range of options.\ninclude_seasons &lt;- c(\"2022-23\", \"2023-24\", \"2024-25\")\n\n# Using Scales to highlight insights to infection trends across seasons.\nplot_A &lt;- df |&gt;\n  # Since we are grouping outcomes by Season, we only need to subset the\n  # dataset to the three seasons we wish to plot.\n  filter(Region == \"Connecticut\", Season %in% include_seasons, Level == \"N/A\") |&gt;\n  # Add the aesthetic mapping that will color (and group) outcomes based\n  # on the unique elements in the Season variable. Also set the y-axis range\n  # and customize plot labels.\n  ggplot(aes(x = MMWRweek, y = Kernel, color = Season) ) +\n    geom_line() + \n    labs(title = \"RSV Infection Trends Since 2022\",\n         x = \"Weeks Since July\", \n         y = \"Positive RSV Tests\\n(scaled and kernel smoothed)\") +\n    ylim(0, 100)\n    # Notice that we do not need to specify a scale_color_*() because\n    # we want this plot to use the default color palette.\n\n\n# Customizing the color applied to that grouping by building on the first plot.\nplot_B &lt;- plot_A +\n    # \"Type\" denotes which set of color palette's to choose from. In\n    # this case we are choosing from the \"Type = Qualitative\", from\n    # which we can choose the \"Palette = Dark2\".\n    scale_color_brewer(type = \"qual\", palette = \"Dark2\")\n\n\n\n\n\n\n\n\n\n\nDiscussion: We see that associating a variable with an aes(color) will also group by that same variable.\n\nWhat would happen if we only group the outcomes and exclude the color statement: i.e.¬†aes(group = Season)?\nDoes adding a scale_color_*() statement change the result?\nWhy do you see the result you get?\n\n\n\n\n\n\n\nImportant\n\n\n\nScales allows you to modify the limits of axes (i.e.¬†with lims() or *lim()) giving the illusion that you can ‚Äúzoom‚Äù into the plot. This is not a good use of the Scales layer, as it will sometimes have the unintended effect of distorting your result. Instead use the Coordinates layer to zoom into a select portion of your plot.\n\n\n\n\n\n\n\n\nCode Like a Pro\n\n\n\nggplot2 does not give users a way to combine multiple plots together into one composite figure that is publication-ready. Fortunately, the community developed ggplot2 extension, cowplot, was created specifically to support generating publication-quality figures. This is the package extension I used to generate plots A and B in the recent example!\ncowplot pkgdown page developed by Professor Claus Wilke at the University of Texas at Austin.\n\n\n\n\nThe Facets Layer\nIn the recent section, we showed how we can use Scales to highlight differences in infection trends between seasons. Doing so will plot the results on the same object, but what if we want to separate group comparisons over multiple plots?\nTechnically, we could code a new plot for each discrete subgrouping of our data that we want to spread out. If each plot is comprised of the same elements and aesthetic settings, however, there is an easier way to achieve the same result. The Facets layer allows us to generate a matrix grid showing the exact same plot for each subgroup available in a discrete variable.\nSimilar to the Scales layer, each plot object we compose implicitly assigns the faceting to NULL by default. The user only needs to include a Facets layer expression if they wish to change the default settings.\n\n# The default faceting is automatically applied.\ndf |&gt;\n  filter(Region == \"Connecticut\", Season %in% include_seasons, Level == \"N/A\") |&gt;\n  ggplot(aes(x = MMWRweek, y = Kernel, color = Season) ) +\n    geom_line() +\n    labs(title = \"RSV Infection Trends Since 2022\",\n         x = \"Weeks Since July\", \n         y = \"Positive RSV Tests\\n(scaled and kernel smoothed)\") +\n    ylim(0, 100) +\n    scale_color_brewer(type = \"qual\", palette = \"Dark2\") +\n    # The following line not required for us to include.\n    facet_null()\n\nThere are two functions for faceting: facet_grid() and facet_wrap(). Both functions receive similar arguments expressed slightly differently, and thus ultimately do the same thing. The biggest difference between them is facet_grid() will divide categories into new columns or rows, while facet_wrap() will optimize the matrix output into a roughly rectangular view.\nIt is best practice to choose the right faceting function based on how long the array of discrete outcomes you will be showing is. In our case, we are going to further resolve comparisons of RSV infections by seasons to include an additional comparison between a selection of age groups. The dataset includes seven age groups, but we are primarily interested in comparing infection trends in children, adults, and the elderly. We will therefore, only be plotting three different groups, making facet_grid() and acceptable function to use.\nfacet_grid() allows us to specify how the subplots are organized: by new columns or new rows. It is possible to compare as many as two variables by separating one over new columns and another over new rows: facet_grid(rows ~ columns). We will separate out the age groups over new columns by dictating facet_grid(~Level). Notice that we want to specify the order we see these panels, which we can do by wrapping our variable name with factor(Level, levels = ordered_vector).\n\n# Create our ordered vector that will be used in factor().\nages_ordered &lt;- c(\"5-17 Years\", \"18-49 Years\", \"75+ Years\")\n\n# Add column-wise faceting.\ndf |&gt;\n  # We only want to maintain three of the seven age groups recorded. We can\n  # use the same variable we generate above to select these.\n  filter(Region == \"Connecticut\", Season %in% include_seasons, Level %in% ages_ordered) |&gt;\n  ggplot(aes(x = MMWRweek, y = Kernel, color = Season) ) +\n    geom_line() +\n    labs(title = \"RSV Infection Trends Since 2022\",\n         x = \"Weeks Since July\", \n         y = \"Positive RSV Tests\\n(scaled and kernel smoothed)\") +\n    ylim(0, 100) +\n    scale_color_brewer(type = \"qual\", palette = \"Dark2\") +\n    # Use \"~Level\" instead of \"Level~\" to create new plots as columns.\n    facet_grid(~factor(Level, levels = ages_ordered))\n\n\n\n\n\n\n\n\n\n\nThe Coordinates Layer\nUp until this point, we have covered layers that attribute variables to geometric-specific aesthetics in Mappings and transformations that interpret those assignments into plottable values in Statistics and Scales. The Geometry layer does a combination of statistical transformations and positioning, preparing the attributed variables into values that will take the chart shape we are looking to create.\nIt is the Coordinates layer that then plots these values on a graph. It‚Äôs important to appreciate this subtlety because some scaled or statistically transformed values will look entirely different if the wrong coordinate system is applied. Such as, if we attempted to plot an angle on a Cartesian plane in Euclidean space instead of in polar coordinates.\n\n\n\nFigure 5.5 from ‚ÄúData Visualization: From Theory to Practice‚Äù by James Baglin. Accessed March 22nd, 2025.\n\n\nCoordinate layer functions fall into two buckets:\n\nLinear: coord_cartesian(), coord_flip(), and coord_fixed()\nNon-linear: coord_map()/coord_quickmap()/coord_sf(), coord_polar(), and coord_trans()\n\nApplying the Cartesian, polar, and transformed coordinates is reasonably straightforward, and we will introduce the topic of map projections today. Keep in mind that the Coordinate layer plays an abstract role in the plot composite making for some key application notes that the user will need to be aware of. More on this subject can be explored in Chapter 15 Coordinate systems of ggplot2: Elegant Graphics for Data Analysis.\nPreviously, we mentioned that axis limits can be applied in Scales, but by doing so we unintentionally skew the results. Instead, it is better to ‚Äúzoom‚Äù into a plot using the Coordinates layer. In a similar vein, if we want to swap the axes our x and y variables get plotted to, we want to use coord_flip() instead of changing aes(x = x_var, y = y_var) to aes(x = y_var, y = x_var).\n\n# By default, plots are generated on non-transformed Cartesian coordinates.\ndf |&gt;\n  filter(Region == \"Connecticut\", Season %in% include_seasons, Level %in% ages_ordered) |&gt;\n  ggplot(aes(x = MMWRweek, y = Kernel, color = Season) ) +\n    geom_line() +\n    labs(title = \"RSV Infection Trends Since 2022\",\n         x = \"Weeks Since July\", \n         y = \"Positive RSV Tests\\n(scaled and kernel smoothed)\") +\n    ylim(0, 100) +\n    scale_color_brewer(type = \"qual\", palette = \"Dark2\") +\n    facet_grid(~factor(Level, levels = ages_ordered)) +\n    # The following line not required for us to include.\n    coord_cartesian()\n\n\n\n\n\n\n\nCode Like a Pro\n\n\n\nAs with any grammar, there are different ways we can make a statement. Say we have a variable that plots with a curve, and you know that you can linearize it using a base 10 \\log. We now have three approaches to graphically representing its linearized transformation. This example is from the coord_trans() documentation, Transformed Cartesian coordinate system.\n\nTransform before plotting or in aes() with log10(). NOTE: only do simple transformations in aes(), like a \\log_{10} transformation, and leave more complicated operations to more robust methods.\nScales: scale_*_log10() or scale_*_continuous(trans = \"log10\")\nCoordinates: coord_trans(* = \"log10\")\n\nDiscussion: If we apply each option individually, do they all plot the same way? If not, what do you think is happening and how would you fix the code?\n\n\n\n\nThe Theme Layer\nThe Theme layer gives the users control over non-data aspects of the plot: i.e.¬†styling the fonts, axes ticks, panel strips, backgrounds, location (or the exclusion) of the legend, etc. It is used to format the plot, making it visually appealing or match intended design schemes. Unlike every other layer described, Theme will not change how values are transformed, their perceptual properties, or how geometries get rendered.\nHow the user intends to use Themes will depend on where in the data processing cycle they are performing visualization, and how they want their polished plots to look. It is therefore not likely to be helpful if I get granular about the different function arguments in Themes. Instead, I encourage students to explore the layer reference page, where they can peruse details for all the possible function arguments at their leisure: Modify components of a theme.\nggplot2 comes with numerous theme that get installed with the package: Complete themes. There are also numerous community developed themes that you can load, some of which have been curated by R Charts: Themes in ggplot2.\nEach time you make a plot, the default is theme_gray(). As before, you do not need to explicitly write this out if you do not intend to change the default settings. In our example, we want use another, more visually appealing theme that better displays our results. We will use another ggplot provided theme: theme_linedraw().\n\n# Using one of ggplot2's provided theme presets.\ndf |&gt;\n  filter(Region == \"Connecticut\", Season %in% include_seasons, Level %in% ages_ordered) |&gt;\n  ggplot(aes(x = MMWRweek, y = Kernel, color = Season) ) +\n    geom_line() +\n    labs(title = \"RSV Infection Trends Since 2022\",\n         x = \"Weeks Since July\", \n         y = \"Positive RSV Tests\\n(scaled and kernel smoothed)\") +\n    ylim(0, 100) +\n    scale_color_brewer(type = \"qual\", palette = \"Dark2\") +\n    facet_grid(~factor(Level, levels = ages_ordered)) + \n    # Add the Themes layer at the end of our plot object expression.\n    theme_linedraw()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode Like a Pro\n\n\n\nSay you regularly generate plots that you want to apply the same custom Theme settings to, such as producing visualizations for a group that has specific branding or plots for a cohesive publication. There are two possible solutions you can take that will obviate the need to rewrite the same theme settings in each plot object.\n\ntheme_set() allows you to set a new theme globally, overriding the default theme settings for the environment: Get, set, and modify the active theme.\nCreating your own custom theme function by modify an existing theme_*() or writing one from scratch: Learning to create custom themes in ggplot by Maddie Pickens and Chapter 20.1 New Themes of ggplot2: Elegant Graphics for Data Analysis.\n\n\n\n\n\nOverlaying Layers\nNow that we have become acclimated to each layer that constitutes one cohesive graph, we are ready to discuss how to effectively build more complex graphs by overlaying additional layers. Earlier I hinted that the expressions for each layer stands alone as its own object in the programming environment. When a graph is rendered by ggplot2 its going to compress these layers one on top of another sequentially.\nThis is all well and good if the plots we are generating contain the same Data and Mapping settings, but what if they do not? What if we want to plot a new Geometry or Statistic layer that doesn‚Äôt use the same settings used by other layers? Every time you add a new layer, you have the opportunity to override the inherited settings that were given in the leading plot object, ggplot().\nFor example, consider the following code. What happens if we change aspects of the Data and Mapping used by geom_line()?\n\nggplot(df, aes(x = MMWRweek, y = Kernel)) + \n  geom_line()\n\n\nOverriding ggplot()table from 13.4 Aesthetic mappings in ggplot2: Elegant Graphics for Data Analysis.\n\n\nOperation\nLayer aesthetics\nResult\n\n\n\n\nAdd\naes(colour = Season)\naes(x = MMWRweek, y = Kernel, colour = Season)\n\n\nOverride\naes(y = Level)\naes(x = MMWRweek, y = Level)\n\n\nRemove\naes(y = NULL)\naes(x = MMWRweek)\n\n\n\nIt is therefore best practice to assign the Data or Mapping in the leading ggplot() plot object when you want those settings carried forward to all subsequent layers. When you need to specify new settings for select Geometric or Statistic layers, then you can specify those mappings in that layer, overriding any previous designation. You can find more information about plot object layering in ggplot in Chapter 13 Build a plot layer by layer in ggplot2: Elegant Graphics for Data Analysis.\n\n\n\n\n\n\nCode Like a Pro\n\n\n\nThe ability to treat each layer as its own object in the coding environment allows for flexible and adaptive programming. For example, you can predefined the settings to generating a smoothed line that you apply to different ggplot() objects, leaning on inherited Data and/or aesthetics Mappings given in each.\nYou can find more information about plot object layering in ggplot in Chapter 18 Programming with ggplot2 in ggplot2: Elegant Graphics for Data Analysis.\n\n\nTo exhibit this in our running example, let‚Äôs add our pi√®ce de r√©sistance, the cherry on top, a leading point highlighting the most recently recorded surveillance week. In order to isolate this exact point, we need to prepare a different subset from the same dataset. We do this by filtering for the same distinguishing variables (Region, Season, and Characteristic Level), followed by filtering to the current infections season, and then finally the most recent week recorded.\nThis point is added to our graph as a fresh layer that is printed on the plot object generated up to the geom_line() expression. In the function settings, we override the inherited Data object and leave the Mappings blank, allowing the aesthetics settings to be inherited from the ggplot() object.\n\n# Subset the dataset to isolate the leading data point we wish to plot.\nleading_point = df |&gt; \n  filter(Region == \"Connecticut\", Season %in% include_seasons, Level %in% ages_ordered) |&gt;\n  filter(MMWRyear == max(MMWRyear)) |&gt;\n  filter(MMWRweek == max(MMWRweek))\n\n# Add a new Geometry layer, geom_point(), using a new dataset.\ndf |&gt;\n  filter(Region == \"Connecticut\", Season %in% include_seasons, Level %in% ages_ordered) |&gt;\n  ggplot(aes(x = MMWRweek, y = Kernel, color = Season) ) +\n    geom_line() +  \n    # Show the leading point as a red dot using the leading_point subset.\n    geom_point(data = leading_point, color = \"red\") +\n    labs(title = \"RSV Infection Trends Since 2022\",\n         x = \"Weeks Since July\", \n         y = \"Positive RSV Tests\\n(scaled and kernel smoothed)\") +\n    ylim(0, 100) +\n    scale_color_brewer(type = \"qual\", palette = \"Dark2\") +\n    facet_grid(~factor(Level, levels = ages_ordered)) + \n    theme_linedraw()\n\n\n\n\n\n\n\n\nLook at us, we are such ggplot experts now! High five! Oh wait a second, for some of you this is asynchronous material‚Ä¶ give yourself a high five for me üëç",
    "crumbs": [
      "Data Visualization with ggplot2",
      "Worked Through Example"
    ]
  },
  {
    "objectID": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html#advanced-uses-of-ggplot2",
    "href": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html#advanced-uses-of-ggplot2",
    "title": "Worked Through Example",
    "section": "Advanced Uses of ggplot2()",
    "text": "Advanced Uses of ggplot2()\nIn this section we will cover two advanced uses of ggplot2 commonly used in public health: projecting data into a map and making the values interactive. These are topics well worth their own workshop, and I will not have time to do them justice here.\nThe goal of the next two sections will be to introduce you to these rich topics. At the end of this section, you will hopefully find these topics more approachable and are better equip to use them in your own work.\n\nIntroduction to Map Projections with ggoplot\nCanonically, map projections are interpreting the curved surface of the earth into a flat plane. For our purposes, we need to render the polygons that represent this projection and associate them with metadata that will visualization our data. ggplot2 comes with two different methods to do both these steps: geom_polygon() or geom_sf().\nThe first is not as robust as the second and, in fact, the second method is recommended by the ggplot2 developers over geom_polygon() for this reason. We are therefore only going to cover geom_sf().\nBefore we apply this function, let‚Äôs think first about what we are doing. Previously I mentioned that map projections are interpreting a curved shape into a flat plane. This projection will give us boundary points that are plotable on a linear Cartesian plane, called polygons. ‚ÄúSimple features‚Äù, from which we get ‚Äúsf‚Äù, are standard vector data produced by the Open Geospatial Consortium (OGC) that interpret this action into plotable polygons.\nUnfortunately, getting a file that contains the region boundaries we are looking for is a rather, shall we say, winding task. This problem gets compounded if we need our resource to contain granular information about the region, such as rivers, lakes, and topology, or even man-made infrastructure, such as roads, cities, or census boundaries.\nWe‚Äôre not going to bother with this problem for now. Our dataset contains information about select contiguous U.S. states, and batches those trends into the HHS regions. Even though we do not need to be immediately concerned with how to plot Alaska and Hawaii into the same figure, we will include that as well.\nHere, we will reference the Topologically Integrated Geographic Encoding and Referencing, or TIGER/Line Shapefiles, provided by the U.S. Census Bureau. The R package tigris allows us to pull these files from the U.S. Census Bureau website and process them for our application.\n\n# Call the TIGER/Line Shapefiles from the Census Bureau.\nus_geo &lt;- tigris::states(class = \"sf\", cb = TRUE) |&gt;\n  # Translate the geometric locations for Alaska and Hawaii to plot underneath\n  # the contiguous states.\n  shift_geometry()\n\nhead(us_geo)\n\n\n\nSimple feature collection with 6 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -2356114 ymin: -782290.7 xmax: 1419556 ymax: 970427.9\nProjected CRS: USA_Contiguous_Albers_Equal_Area_Conic\n  STATEFP  STATENS     GEOIDFQ GEOID STUSPS         NAME LSAD        ALAND\n1      35 00897535 0400000US35    35     NM   New Mexico   00 314198519809\n2      46 01785534 0400000US46    46     SD South Dakota   00 196341670967\n3      06 01779778 0400000US06    06     CA   California   00 403673433805\n4      21 01779786 0400000US21    21     KY     Kentucky   00 102266755818\n5      01 01779775 0400000US01    01     AL      Alabama   00 131185561946\n6      13 01705317 0400000US13    13     GA      Georgia   00 149485762701\n       AWATER                       geometry\n1   726531289 MULTIPOLYGON (((-1231344 -5...\n2  3387563375 MULTIPOLYGON (((-633765.6 8...\n3 20291632828 MULTIPOLYGON (((-2066923 -2...\n4  2384136185 MULTIPOLYGON (((584560 -886...\n5  4581813708 MULTIPOLYGON (((760323.7 -7...\n6  4419221858 MULTIPOLYGON (((1390722 -58...\n\n\nIn this dataset, we see that there are various state identifiers\n\nSTATEFP - Federal Information Processing System (FIPS) ID\nSTATENS - United States Geological Survey (USGS) ID\nAFFGEOID - American Fact Finder Geographic Identifiers\nGEOID - the standard geographic identifiers\n\nand land type identifiers\n\nLSAD - Legal/Statistical Area Description (LSAD)\nALAND - land size in square miles\nAWATER - water size in square miles\nGeometry - the longitude and latitude for the polygon vertices.\n\nTogether, these are used by geom_sf() to create map projections out of our spacial data. And believe it or not, that was the hardest part about map projections. Once we have these polygons, we are well on our way to visualizing our data on a map.\nGoing back to our running example, let‚Äôs show the distribution of infection trends near the peak of the 2024-25 season, around weeks 24 to 26.\n\nsubset &lt;- df |&gt;\n  # Keep only the states and the timeframe we want to plot.\n  filter(Region %in% c(datasets::state.name, \"District of Columbia\"),\n         Season %in% \"2024-25\", MMWRweek %in% c(24:26))\n\n# Combine the two datasets by Region in df and NAME in us_geo.\ngeo_df &lt;- us_geo |&gt; \n  left_join(subset, c(\"NAME\" = \"Region\")) |&gt;\n  # Using GEOID, we will only keep the U.S. states.\n  filter(GEOID &lt; 60)\n\nmap_plot &lt;- geo_df |&gt;\n  # Color the polygon with the number of RSV positives tested.\n  ggplot(aes(fill = Kernel), color = \"black\") +\n    # Apply the SF compatible Geometry.\n    geom_sf() +\n    # Scale the aesthetics to apply the viridis colors and do not\n    # add colors for the NA's\n    scale_fill_viridis(direction = -1, na.value = \"grey92\") +\n    labs(fill = NULL, title = \"Peak 2024-25 Season RSV Infection Trends\\nResults Scaled and Gaussian Kernel Smoothed\") +\n    # Apply the SF compatible Coordinates.\n    coord_sf() +\n    theme_map()\n\nmap_plot\n\n\n\n\n\n\n\n\nVoil√†!\n\n\n\n\n\n\nGeometry and Statistic Layers Dictate the Aesthetics Mapping\n\n\n\nggplot is a convenient way to render a plot, but it is not the most efficient package option out there! If you are looking for something that is faster and more flexible, you might want to check out packages like leaflet (Cran R documentation).\n\n\n\n\nIntroduction to Interactive Plotting with plotly\nA static graphic can communicate a lot about your data, but with html widgets, like plotly, you can make the plot user interactive. These widgets allow actions like zooming, hovering, and selecting variables in the legend to be displayed. There are different widgets to choose from, and usually you will pick one that is best suited to make the graphic you intend. You can find some inspiration from the R Graph Gallery.\nToday, I will show you how to apply one of the most commonly used interactive packages, plotly. This package is cross platform compatible and can be used in Python, Julia, and MATLAB. It has its own standalone function for plot generation that come with more options, but if you are looking to quickly make a ggplot() interactive all you need to do is wrap it with ggplotly().\nYou can find more about plotly and the kinds of interactive plots it can generate with ggplot() objections in their documentation: Plotly R Open Source Graphing Library and Plotly ggplot2 Open Source Graphing Library.\n\nggplotly(map_plot)",
    "crumbs": [
      "Data Visualization with ggplot2",
      "Worked Through Example"
    ]
  },
  {
    "objectID": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html#yales-clarity-ai",
    "href": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html#yales-clarity-ai",
    "title": "Worked Through Example",
    "section": "Yale‚Äôs Clarity AI",
    "text": "Yale‚Äôs Clarity AI\nWe will now ask Yale‚Äôs Clarity Platform to reproduce the code from one of our plots using the image alone.\n\nTake a screenshot of one of the plots from the workshop or one of your own.\nNavigate to ai-chat.yale.edu/signin-oidc.\nUpload the screenshot into the chat and ask ‚Äù Suggest R code that could make this plot in ggplot2.‚Äù\n\nDiscussion: How did the AI chatbot do?",
    "crumbs": [
      "Data Visualization with ggplot2",
      "Worked Through Example"
    ]
  },
  {
    "objectID": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html#challenge-questions",
    "href": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html#challenge-questions",
    "title": "Worked Through Example",
    "section": "Challenge Questions",
    "text": "Challenge Questions\nYou can find the code for these questions and their suggested solutions in Discussion and Challenge Questions.R.\n\nIn the worked through example we leverage two of the three distinguishing variables: Season and Characteristic Level. In this questions, we want to focus on the third one, Region. Using the final line-graph code from the worked through example, add a row-wise facet to compare two states or HHS regions.\nIn the polished version of the line plot we layered an additional point on the graph that highlighted the most currently represented date in the active infection season. To get this data, we externally filtered down the dataset to give that point, repeating some of the filtering we are already doing before the plot gets generated.\n\nCan you modify this approach so that we no longer require the external dataset, thus simplifying our code?\nNow try using stat_summary(filtered_data, geom = \"point\", fun = \"max\", color = \"red\") instead of geom_point(). If you only filter to MMWRyear, do you get the same result, and if not why?\n\nIn our line graph we faceted by age groups. But we see that if we apply a simple Facet layer to our map plot the NA values get plotted in their own panel.\n\nWhy is this happening?\nFix this code to prevent this panel from being generated.",
    "crumbs": [
      "Data Visualization with ggplot2",
      "Worked Through Example"
    ]
  },
  {
    "objectID": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html#appendix",
    "href": "Data-Visualization-with-ggplot2/Pages/visualization-worked-through-example.html#appendix",
    "title": "Worked Through Example",
    "section": "Appendix",
    "text": "Appendix\nThis workshop was generated using R (v 4.4.4) in the RStudio IDE (v 2024.12.1+563). renv was used to store all the relevant packages and package versions with the workshop codespace. All of the workshop materials can be accessed on the ysph-dsde GitHub: Data Visualization with ggplo2. All relevant citations for this document can be found in the Appendix of the slides.\nThis site was built on a ysph-dsde.github.io page. It was rendered using Quarto (v 1.6.3) and theme sandstone.",
    "crumbs": [
      "Data Visualization with ggplot2",
      "Worked Through Example"
    ]
  }
]